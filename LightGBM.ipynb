{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c319ce-9d88-4084-a768-18a6045bb136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载成功 (UTF-8)\n",
      "原始数据总量: 816\n",
      "用于调优和CV的训练集 (80%): 652\n",
      "独立测试集 (20%): 164\n",
      "\n",
      "==================================================\n",
      ">>> Stage 1: 开始 LightGBM 贝叶斯优化 (BayesSearchCV)...\n",
      "==================================================\n",
      "贝叶斯优化耗时: 59.95 秒\n",
      "\n",
      ">>> 最佳参数:\n",
      "  regressor__learning_rate: 0.13254000461783513\n",
      "  regressor__max_depth: 15\n",
      "  regressor__min_child_samples: 5\n",
      "  regressor__n_estimators: 100\n",
      "  regressor__num_leaves: 46\n",
      "  regressor__reg_alpha: 0.0\n",
      "  regressor__reg_lambda: 1.0\n",
      "\n",
      "==================================================\n",
      ">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\n",
      "==================================================\n",
      "Fold 1/10 完成 | Val R2: 0.7496\n",
      "Fold 2/10 完成 | Val R2: 0.7401\n",
      "Fold 3/10 完成 | Val R2: 0.7998\n",
      "Fold 4/10 完成 | Val R2: 0.8806\n",
      "Fold 5/10 完成 | Val R2: 0.8647\n",
      "Fold 6/10 完成 | Val R2: 0.9020\n",
      "Fold 7/10 完成 | Val R2: 0.7736\n",
      "Fold 8/10 完成 | Val R2: 0.7229\n",
      "Fold 9/10 完成 | Val R2: 0.8820\n",
      "Fold 10/10 完成 | Val R2: 0.7713\n",
      "\n",
      ">>> 十折交叉验证详细结果 (Per-Fold Results):\n",
      "       Fold  Train R2  Train RMSE  Train MAE  Val R2  Val RMSE  Val MAE\n",
      "0         1    0.9979      0.0334     0.0215  0.7496    0.3826   0.2154\n",
      "1         2    0.9971      0.0407     0.0241  0.7401    0.2784   0.1380\n",
      "2         3    0.9971      0.0397     0.0239  0.7998    0.3198   0.1749\n",
      "3         4    0.9969      0.0415     0.0247  0.8806    0.2169   0.1440\n",
      "4         5    0.9976      0.0364     0.0221  0.8647    0.2318   0.1394\n",
      "5         6    0.9966      0.0399     0.0226  0.9020    0.3434   0.2144\n",
      "6         7    0.9973      0.0390     0.0232  0.7736    0.3244   0.2029\n",
      "7         8    0.9970      0.0412     0.0245  0.7229    0.3015   0.1631\n",
      "8         9    0.9969      0.0408     0.0239  0.8820    0.2682   0.1573\n",
      "9        10    0.9972      0.0390     0.0234  0.7713    0.3751   0.1986\n",
      "10  Average    0.9972      0.0391     0.0234  0.8087    0.3042   0.1748\n",
      "\n",
      "==================================================\n",
      ">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\n",
      "==================================================\n",
      "\n",
      ">>> 模型性能最终汇总 (LightGBM + BayesOpt):\n",
      "  Metric  CV Training (Avg)  CV Validation (Avg)  Test Set (Final)\n",
      "0    MAE             0.0234               0.1748            0.1513\n",
      "1   RMSE             0.0391               0.3042            0.2316\n",
      "2     R2             0.9972               0.8087            0.8788\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 引入贝叶斯优化库\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ==========================================\n",
    "# 1. 数据加载与分割 (80:20)\n",
    "# ==========================================\n",
    "file_path = 'C:/Users/tinid/polymer/major revision/标准化数据_无独热_Log变换12.18.csv'\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"数据加载成功 (UTF-8)\")\n",
    "except UnicodeDecodeError:\n",
    "    data = pd.read_csv(file_path, encoding='gbk')\n",
    "    print(\"数据加载成功 (GBK)\")\n",
    "\n",
    "excluded_columns = ['log_Separation factor', 'polymer', 'DOI', 'Flux']\n",
    "X = data.drop(columns=excluded_columns, errors='ignore')\n",
    "y = data['log_Separation factor']\n",
    "\n",
    "# 划分出 20% 的独立测试集 (Test Set)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"原始数据总量: {len(X)}\")\n",
    "print(f\"用于调优和CV的训练集 (80%): {len(X_train_full)}\")\n",
    "print(f\"独立测试集 (20%): {len(X_test)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 构建预处理与模型流水线\n",
    "# ==========================================\n",
    "categorical_features = ['Permeation type']\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# 定义预处理器\n",
    "# 数值列：直接通过 (passthrough)，因为已经标准化过\n",
    "# 分类列：独热编码 (OneHotEncoder)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 定义 Pipeline: 预处理 -> LightGBM\n",
    "# 注意：LightGBM 的 sklearn 接口是 LGBMRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', lgb.LGBMRegressor(random_state=42, verbose=-1))\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 3. 第一阶段：贝叶斯超参数优化\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 1: 开始 LightGBM 贝叶斯优化 (BayesSearchCV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 定义搜索空间\n",
    "# LightGBM 的核心参数：num_leaves 和 max_depth 需要配合调整\n",
    "search_spaces = {\n",
    "    'regressor__learning_rate': Real(0.01, 0.3, prior='log-uniform'), # 学习率\n",
    "    'regressor__n_estimators': Integer(100, 1000),       # 树的数量\n",
    "    'regressor__num_leaves': Integer(20, 100),           # 叶子节点数 (控制复杂度)\n",
    "    'regressor__max_depth': Integer(3, 15),              # 树深度\n",
    "    'regressor__min_child_samples': Integer(5, 50),      # 叶节点最小样本数 (防过拟合)\n",
    "    'regressor__reg_alpha': Real(0.0, 1.0),              # L1 正则化\n",
    "    'regressor__reg_lambda': Real(0.0, 1.0)              # L2 正则化\n",
    "}\n",
    "\n",
    "# 初始化贝叶斯搜索\n",
    "opt = BayesSearchCV(\n",
    "    pipeline,\n",
    "    search_spaces,\n",
    "    n_iter=30,      # 迭代 30 次\n",
    "    cv=5,           # 调优阶段内部 5 折\n",
    "    n_jobs=-1,      # 并行计算\n",
    "    random_state=42,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "opt.fit(X_train_full, y_train_full)\n",
    "end_time = time.time()\n",
    "\n",
    "best_estimator = opt.best_estimator_ # 包含预处理的完整 Pipeline\n",
    "best_params = opt.best_params_\n",
    "\n",
    "print(f\"贝叶斯优化耗时: {end_time - start_time:.2f} 秒\")\n",
    "print(\"\\n>>> 最佳参数:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 第二阶段：十折交叉验证 (使用最佳参数)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_full)):\n",
    "    # 4.1 切分数据\n",
    "    X_train_fold = X_train_full.iloc[train_idx]\n",
    "    y_train_fold = y_train_full.iloc[train_idx]\n",
    "    X_val_fold = X_train_full.iloc[val_idx]\n",
    "    y_val_fold = y_train_full.iloc[val_idx]\n",
    "    \n",
    "    # 4.2 克隆最佳模型 (确保每一折独立训练)\n",
    "    model = clone(best_estimator)\n",
    "    \n",
    "    # 4.3 训练 (Pipeline 自动处理 OneHot)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 4.4 预测\n",
    "    y_train_pred = model.predict(X_train_fold)\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    \n",
    "    # 4.5 记录指标\n",
    "    metrics = {\n",
    "        \"Fold\": fold + 1,\n",
    "        \"Train R2\": r2_score(y_train_fold, y_train_pred),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train_fold, y_train_pred)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train_fold, y_train_pred),\n",
    "        \"Val R2\": r2_score(y_val_fold, y_val_pred),\n",
    "        \"Val RMSE\": np.sqrt(mean_squared_error(y_val_fold, y_val_pred)),\n",
    "        \"Val MAE\": mean_absolute_error(y_val_fold, y_val_pred)\n",
    "    }\n",
    "    fold_results.append(metrics)\n",
    "    print(f\"Fold {fold+1}/10 完成 | Val R2: {metrics['Val R2']:.4f}\")\n",
    "\n",
    "# 输出详细表格\n",
    "df_cv_results = pd.DataFrame(fold_results)\n",
    "avg_row = df_cv_results.mean(numeric_only=True).to_frame().T\n",
    "avg_row[\"Fold\"] = \"Average\"\n",
    "df_final_cv = pd.concat([df_cv_results, avg_row], ignore_index=True)\n",
    "\n",
    "print(\"\\n>>> 十折交叉验证详细结果 (Per-Fold Results):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df_final_cv.round(4))\n",
    "\n",
    "# ==========================================\n",
    "# 5. 第三阶段：独立测试集最终评估\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 使用 80% 的全量数据重新训练最佳模型\n",
    "best_estimator.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 在 20% 独立测试集上预测\n",
    "y_test_pred = best_estimator.predict(X_test)\n",
    "\n",
    "final_summary = {\n",
    "    \"Metric\": [\"MAE\", \"RMSE\", \"R2\"],\n",
    "    \"CV Training (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Train MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Train RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Train R2\"]\n",
    "    ],\n",
    "    \"CV Validation (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Val MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Val RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Val R2\"]\n",
    "    ],\n",
    "    \"Test Set (Final)\": [\n",
    "        mean_absolute_error(y_test, y_test_pred),\n",
    "        np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        r2_score(y_test, y_test_pred)\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n>>> 模型性能最终汇总 (LightGBM + BayesOpt):\")\n",
    "print(pd.DataFrame(final_summary).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ea763a-6f8b-4f78-8fc6-9105650dfc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据总量: 791\n",
      "用于调优和CV的训练集 (80%): 632\n",
      "独立测试集 (20%): 159\n",
      "\n",
      "==================================================\n",
      ">>> Stage 1: 开始 LightGBM 贝叶斯优化 (BayesSearchCV)...\n",
      "==================================================\n",
      "贝叶斯优化耗时: 42.96 秒\n",
      "\n",
      ">>> 最佳参数:\n",
      "  regressor__learning_rate: 0.07743392536999648\n",
      "  regressor__max_depth: 15\n",
      "  regressor__min_child_samples: 5\n",
      "  regressor__n_estimators: 1000\n",
      "  regressor__num_leaves: 20\n",
      "  regressor__reg_alpha: 0.0\n",
      "  regressor__reg_lambda: 0.0\n",
      "\n",
      "==================================================\n",
      ">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\n",
      "==================================================\n",
      "Fold 1/10 完成 | Val R2: 0.5279\n",
      "Fold 2/10 完成 | Val R2: 0.8556\n",
      "Fold 3/10 完成 | Val R2: 0.5154\n",
      "Fold 4/10 完成 | Val R2: 0.7129\n",
      "Fold 5/10 完成 | Val R2: 0.6911\n",
      "Fold 6/10 完成 | Val R2: 0.8458\n",
      "Fold 7/10 完成 | Val R2: 0.7444\n",
      "Fold 8/10 完成 | Val R2: 0.8097\n",
      "Fold 9/10 完成 | Val R2: 0.7607\n",
      "Fold 10/10 完成 | Val R2: 0.7462\n",
      "\n",
      ">>> 十折交叉验证详细结果 (Per-Fold Results):\n",
      "       Fold  Train R2  Train RMSE  Train MAE  Val R2  Val RMSE  Val MAE\n",
      "0         1    0.9974      0.0317     0.0085  0.5279    0.4090   0.2427\n",
      "1         2    0.9975      0.0317     0.0085  0.8556    0.2191   0.1599\n",
      "2         3    0.9975      0.0315     0.0080  0.5154    0.3775   0.2056\n",
      "3         4    0.9973      0.0317     0.0087  0.7129    0.4037   0.2364\n",
      "4         5    0.9996      0.0119     0.0068  0.6911    0.3558   0.2315\n",
      "5         6    0.9992      0.0178     0.0074  0.8458    0.2403   0.1655\n",
      "6         7    0.9996      0.0128     0.0071  0.7444    0.2844   0.1854\n",
      "7         8    0.9974      0.0319     0.0086  0.8097    0.2457   0.1647\n",
      "8         9    0.9991      0.0182     0.0081  0.7607    0.3524   0.2346\n",
      "9        10    0.9975      0.0315     0.0084  0.7462    0.2704   0.1659\n",
      "10  Average    0.9982      0.0251     0.0080  0.7210    0.3158   0.1992\n",
      "\n",
      "==================================================\n",
      ">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\n",
      "==================================================\n",
      "\n",
      ">>> 模型性能最终汇总 (LightGBM + BayesOpt):\n",
      "  Metric  CV Training (Avg)  CV Validation (Avg)  Test Set (Final)\n",
      "0    MAE             0.0080               0.1992            0.1956\n",
      "1   RMSE             0.0251               0.3158            0.2965\n",
      "2     R2             0.9982               0.7210            0.7741\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 引入贝叶斯优化库\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ==========================================\n",
    "# 1. 数据加载与分割 (80:20)\n",
    "# ==========================================\n",
    "file_path = 'C:/Users/tinid/polymer/major revision/通量标准化数据_无独热_Log变换12.18.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define excluded columns (unchanged)\n",
    "excluded_columns = ['log_Flux', 'polymer', 'DOI', 'Separation factor']\n",
    "X = data.drop(columns=excluded_columns, errors='ignore')\n",
    "y = data['log_Flux']\n",
    "\n",
    "# 划分出 20% 的独立测试集 (Test Set)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"原始数据总量: {len(X)}\")\n",
    "print(f\"用于调优和CV的训练集 (80%): {len(X_train_full)}\")\n",
    "print(f\"独立测试集 (20%): {len(X_test)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 构建预处理与模型流水线\n",
    "# ==========================================\n",
    "categorical_features = ['Permeation type']\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# 定义预处理器\n",
    "# 数值列：直接通过 (passthrough)，因为已经标准化过\n",
    "# 分类列：独热编码 (OneHotEncoder)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 定义 Pipeline: 预处理 -> LightGBM\n",
    "# 注意：LightGBM 的 sklearn 接口是 LGBMRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', lgb.LGBMRegressor(random_state=42, verbose=-1))\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 3. 第一阶段：贝叶斯超参数优化\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 1: 开始 LightGBM 贝叶斯优化 (BayesSearchCV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 定义搜索空间\n",
    "# LightGBM 的核心参数：num_leaves 和 max_depth 需要配合调整\n",
    "search_spaces = {\n",
    "    'regressor__learning_rate': Real(0.01, 0.3, prior='log-uniform'), # 学习率\n",
    "    'regressor__n_estimators': Integer(100, 1000),       # 树的数量\n",
    "    'regressor__num_leaves': Integer(20, 100),           # 叶子节点数 (控制复杂度)\n",
    "    'regressor__max_depth': Integer(3, 15),              # 树深度\n",
    "    'regressor__min_child_samples': Integer(5, 50),      # 叶节点最小样本数 (防过拟合)\n",
    "    'regressor__reg_alpha': Real(0.0, 1.0),              # L1 正则化\n",
    "    'regressor__reg_lambda': Real(0.0, 1.0)              # L2 正则化\n",
    "}\n",
    "\n",
    "# 初始化贝叶斯搜索\n",
    "opt = BayesSearchCV(\n",
    "    pipeline,\n",
    "    search_spaces,\n",
    "    n_iter=30,      # 迭代 30 次\n",
    "    cv=5,           # 调优阶段内部 5 折\n",
    "    n_jobs=-1,      # 并行计算\n",
    "    random_state=42,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "opt.fit(X_train_full, y_train_full)\n",
    "end_time = time.time()\n",
    "\n",
    "best_estimator = opt.best_estimator_ # 包含预处理的完整 Pipeline\n",
    "best_params = opt.best_params_\n",
    "\n",
    "print(f\"贝叶斯优化耗时: {end_time - start_time:.2f} 秒\")\n",
    "print(\"\\n>>> 最佳参数:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 第二阶段：十折交叉验证 (使用最佳参数)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_full)):\n",
    "    # 4.1 切分数据\n",
    "    X_train_fold = X_train_full.iloc[train_idx]\n",
    "    y_train_fold = y_train_full.iloc[train_idx]\n",
    "    X_val_fold = X_train_full.iloc[val_idx]\n",
    "    y_val_fold = y_train_full.iloc[val_idx]\n",
    "    \n",
    "    # 4.2 克隆最佳模型 (确保每一折独立训练)\n",
    "    model = clone(best_estimator)\n",
    "    \n",
    "    # 4.3 训练 (Pipeline 自动处理 OneHot)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 4.4 预测\n",
    "    y_train_pred = model.predict(X_train_fold)\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    \n",
    "    # 4.5 记录指标\n",
    "    metrics = {\n",
    "        \"Fold\": fold + 1,\n",
    "        \"Train R2\": r2_score(y_train_fold, y_train_pred),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train_fold, y_train_pred)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train_fold, y_train_pred),\n",
    "        \"Val R2\": r2_score(y_val_fold, y_val_pred),\n",
    "        \"Val RMSE\": np.sqrt(mean_squared_error(y_val_fold, y_val_pred)),\n",
    "        \"Val MAE\": mean_absolute_error(y_val_fold, y_val_pred)\n",
    "    }\n",
    "    fold_results.append(metrics)\n",
    "    print(f\"Fold {fold+1}/10 完成 | Val R2: {metrics['Val R2']:.4f}\")\n",
    "\n",
    "# 输出详细表格\n",
    "df_cv_results = pd.DataFrame(fold_results)\n",
    "avg_row = df_cv_results.mean(numeric_only=True).to_frame().T\n",
    "avg_row[\"Fold\"] = \"Average\"\n",
    "df_final_cv = pd.concat([df_cv_results, avg_row], ignore_index=True)\n",
    "\n",
    "print(\"\\n>>> 十折交叉验证详细结果 (Per-Fold Results):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df_final_cv.round(4))\n",
    "\n",
    "# ==========================================\n",
    "# 5. 第三阶段：独立测试集最终评估\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 使用 80% 的全量数据重新训练最佳模型\n",
    "best_estimator.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 在 20% 独立测试集上预测\n",
    "y_test_pred = best_estimator.predict(X_test)\n",
    "\n",
    "final_summary = {\n",
    "    \"Metric\": [\"MAE\", \"RMSE\", \"R2\"],\n",
    "    \"CV Training (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Train MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Train RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Train R2\"]\n",
    "    ],\n",
    "    \"CV Validation (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Val MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Val RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Val R2\"]\n",
    "    ],\n",
    "    \"Test Set (Final)\": [\n",
    "        mean_absolute_error(y_test, y_test_pred),\n",
    "        np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        r2_score(y_test, y_test_pred)\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n>>> 模型性能最终汇总 (LightGBM + BayesOpt):\")\n",
    "print(pd.DataFrame(final_summary).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4ab14-9415-405e-9a50-b3ab9620751d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
