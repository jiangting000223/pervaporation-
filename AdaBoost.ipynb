{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218f76e4-5fa6-4436-a106-4f31acb7525e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载成功 (UTF-8)\n",
      "原始数据总量: 816\n",
      "用于调优和CV的训练集 (80%): 652\n",
      "独立测试集 (20%): 164\n",
      "\n",
      "==================================================\n",
      ">>> Stage 1: 开始 AdaBoost 贝叶斯优化 (BayesSearchCV)...\n",
      "==================================================\n",
      "贝叶斯优化耗时: 69.83 秒\n",
      "\n",
      ">>> 最佳参数:\n",
      "  regressor__estimator__max_depth: 10\n",
      "  regressor__estimator__min_samples_split: 2\n",
      "  regressor__learning_rate: 1.0\n",
      "  regressor__loss: exponential\n",
      "  regressor__n_estimators: 500\n",
      "\n",
      "==================================================\n",
      ">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\n",
      "==================================================\n",
      "Fold 1/10 完成 | Val R2: 0.7607\n",
      "Fold 2/10 完成 | Val R2: 0.7173\n",
      "Fold 3/10 完成 | Val R2: 0.7382\n",
      "Fold 4/10 完成 | Val R2: 0.9030\n",
      "Fold 5/10 完成 | Val R2: 0.8782\n",
      "Fold 6/10 完成 | Val R2: 0.8994\n",
      "Fold 7/10 完成 | Val R2: 0.8066\n",
      "Fold 8/10 完成 | Val R2: 0.7713\n",
      "Fold 9/10 完成 | Val R2: 0.8946\n",
      "Fold 10/10 完成 | Val R2: 0.7552\n",
      "\n",
      ">>> 十折交叉验证详细结果 (Per-Fold Results):\n",
      "       Fold  Train R2  Train RMSE  Train MAE  Val R2  Val RMSE  Val MAE\n",
      "0         1    0.9979      0.0333     0.0204  0.7607    0.3740   0.2084\n",
      "1         2    0.9976      0.0371     0.0233  0.7173    0.2903   0.1575\n",
      "2         3    0.9977      0.0354     0.0220  0.7382    0.3658   0.1908\n",
      "3         4    0.9973      0.0388     0.0243  0.9030    0.1955   0.1278\n",
      "4         5    0.9979      0.0344     0.0209  0.8782    0.2199   0.1338\n",
      "5         6    0.9974      0.0347     0.0218  0.8994    0.3479   0.1905\n",
      "6         7    0.9981      0.0325     0.0197  0.8066    0.2999   0.1765\n",
      "7         8    0.9978      0.0357     0.0226  0.7713    0.2739   0.1542\n",
      "8         9    0.9978      0.0342     0.0212  0.8946    0.2535   0.1507\n",
      "9        10    0.9979      0.0339     0.0209  0.7552    0.3881   0.2011\n",
      "10  Average    0.9977      0.0350     0.0217  0.8124    0.3009   0.1691\n",
      "\n",
      "==================================================\n",
      ">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\n",
      "==================================================\n",
      "\n",
      ">>> 模型性能最终汇总 (AdaBoost + BayesOpt):\n",
      "  Metric  CV Training (Avg)  CV Validation (Avg)  Test Set (Final)\n",
      "0    MAE             0.0217               0.1691            0.1642\n",
      "1   RMSE             0.0350               0.3009            0.2959\n",
      "2     R2             0.9977               0.8124            0.8021\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 引入贝叶斯优化库\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ==========================================\n",
    "# 1. 数据加载与分割 (80:20)\n",
    "# ==========================================\n",
    "file_path = 'C:/Users/tinid/polymer/major revision/标准化数据_无独热_Log变换12.18.csv'\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"数据加载成功 (UTF-8)\")\n",
    "except UnicodeDecodeError:\n",
    "    data = pd.read_csv(file_path, encoding='gbk')\n",
    "    print(\"数据加载成功 (GBK)\")\n",
    "\n",
    "excluded_columns = ['log_Separation factor', 'polymer', 'DOI', 'Flux']\n",
    "X = data.drop(columns=excluded_columns, errors='ignore')\n",
    "y = data['log_Separation factor']\n",
    "\n",
    "# 划分出 20% 的独立测试集 (Test Set)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"原始数据总量: {len(X)}\")\n",
    "print(f\"用于调优和CV的训练集 (80%): {len(X_train_full)}\")\n",
    "print(f\"独立测试集 (20%): {len(X_test)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 构建预处理与模型流水线\n",
    "# ==========================================\n",
    "categorical_features = ['Permeation type']\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# 定义预处理器\n",
    "# 数值列：使用 'passthrough' (因已标准化)\n",
    "# 分类列：OneHotEncoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 定义基学习器 (Base Estimator)\n",
    "# AdaBoost 默认使用 DecisionTreeRegressor(max_depth=3)\n",
    "# 我们将在贝叶斯优化中调整它的 max_depth\n",
    "base_estimator = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# 定义 Pipeline: 预处理 -> AdaBoost\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', AdaBoostRegressor(estimator=base_estimator, random_state=42))\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 3. 第一阶段：贝叶斯超参数优化\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 1: 开始 AdaBoost 贝叶斯优化 (BayesSearchCV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 定义搜索空间\n",
    "# 注意：estimator__max_depth 是指 AdaBoost 内部决策树的深度\n",
    "search_spaces = {\n",
    "    'regressor__n_estimators': Integer(50, 500),          # 迭代次数\n",
    "    'regressor__learning_rate': Real(0.001, 1.0, prior='log-uniform'), # 学习率\n",
    "    'regressor__loss': Categorical(['linear', 'square', 'exponential']), # 损失函数\n",
    "    'regressor__estimator__max_depth': Integer(1, 10),    # 基学习器(树)的深度\n",
    "    'regressor__estimator__min_samples_split': Integer(2, 10) # 防过拟合\n",
    "}\n",
    "\n",
    "# 初始化贝叶斯搜索\n",
    "opt = BayesSearchCV(\n",
    "    pipeline,\n",
    "    search_spaces,\n",
    "    n_iter=30,      # 迭代 30 次\n",
    "    cv=5,           # 调优阶段内部 5 折\n",
    "    n_jobs=-1,      # 并行计算 (AdaBoost fit本身串行，但CV可并行)\n",
    "    random_state=42,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "opt.fit(X_train_full, y_train_full)\n",
    "end_time = time.time()\n",
    "\n",
    "best_estimator = opt.best_estimator_ # 包含预处理的完整 Pipeline\n",
    "best_params = opt.best_params_\n",
    "\n",
    "print(f\"贝叶斯优化耗时: {end_time - start_time:.2f} 秒\")\n",
    "print(\"\\n>>> 最佳参数:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 第二阶段：十折交叉验证 (使用最佳参数)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_full)):\n",
    "    # 4.1 切分数据\n",
    "    X_train_fold = X_train_full.iloc[train_idx]\n",
    "    y_train_fold = y_train_full.iloc[train_idx]\n",
    "    X_val_fold = X_train_full.iloc[val_idx]\n",
    "    y_val_fold = y_train_full.iloc[val_idx]\n",
    "    \n",
    "    # 4.2 克隆最佳模型 (确保每一折独立训练)\n",
    "    model = clone(best_estimator)\n",
    "    \n",
    "    # 4.3 训练 (Pipeline 自动处理 OneHot)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 4.4 预测\n",
    "    y_train_pred = model.predict(X_train_fold)\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    \n",
    "    # 4.5 记录指标\n",
    "    metrics = {\n",
    "        \"Fold\": fold + 1,\n",
    "        \"Train R2\": r2_score(y_train_fold, y_train_pred),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train_fold, y_train_pred)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train_fold, y_train_pred),\n",
    "        \"Val R2\": r2_score(y_val_fold, y_val_pred),\n",
    "        \"Val RMSE\": np.sqrt(mean_squared_error(y_val_fold, y_val_pred)),\n",
    "        \"Val MAE\": mean_absolute_error(y_val_fold, y_val_pred)\n",
    "    }\n",
    "    fold_results.append(metrics)\n",
    "    print(f\"Fold {fold+1}/10 完成 | Val R2: {metrics['Val R2']:.4f}\")\n",
    "\n",
    "# 输出详细表格\n",
    "df_cv_results = pd.DataFrame(fold_results)\n",
    "avg_row = df_cv_results.mean(numeric_only=True).to_frame().T\n",
    "avg_row[\"Fold\"] = \"Average\"\n",
    "df_final_cv = pd.concat([df_cv_results, avg_row], ignore_index=True)\n",
    "\n",
    "print(\"\\n>>> 十折交叉验证详细结果 (Per-Fold Results):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df_final_cv.round(4))\n",
    "\n",
    "# ==========================================\n",
    "# 5. 第三阶段：独立测试集最终评估\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 使用 80% 的全量数据重新训练最佳模型\n",
    "best_estimator.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 在 20% 独立测试集上预测\n",
    "y_test_pred = best_estimator.predict(X_test)\n",
    "\n",
    "final_summary = {\n",
    "    \"Metric\": [\"MAE\", \"RMSE\", \"R2\"],\n",
    "    \"CV Training (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Train MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Train RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Train R2\"]\n",
    "    ],\n",
    "    \"CV Validation (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Val MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Val RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Val R2\"]\n",
    "    ],\n",
    "    \"Test Set (Final)\": [\n",
    "        mean_absolute_error(y_test, y_test_pred),\n",
    "        np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        r2_score(y_test, y_test_pred)\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n>>> 模型性能最终汇总 (AdaBoost + BayesOpt):\")\n",
    "print(pd.DataFrame(final_summary).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1090984-2805-4fe8-b33c-828a52a97c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据总量: 791\n",
      "用于调优和CV的训练集 (80%): 632\n",
      "独立测试集 (20%): 159\n",
      "\n",
      "==================================================\n",
      ">>> Stage 1: 开始 AdaBoost 贝叶斯优化 (BayesSearchCV)...\n",
      "==================================================\n",
      "贝叶斯优化耗时: 66.29 秒\n",
      "\n",
      ">>> 最佳参数:\n",
      "  regressor__estimator__max_depth: 10\n",
      "  regressor__estimator__min_samples_split: 2\n",
      "  regressor__learning_rate: 1.0\n",
      "  regressor__loss: exponential\n",
      "  regressor__n_estimators: 332\n",
      "\n",
      "==================================================\n",
      ">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\n",
      "==================================================\n",
      "Fold 1/10 完成 | Val R2: 0.3909\n",
      "Fold 2/10 完成 | Val R2: 0.8771\n",
      "Fold 3/10 完成 | Val R2: 0.4785\n",
      "Fold 4/10 完成 | Val R2: 0.6297\n",
      "Fold 5/10 完成 | Val R2: 0.6821\n",
      "Fold 6/10 完成 | Val R2: 0.8373\n",
      "Fold 7/10 完成 | Val R2: 0.7180\n",
      "Fold 8/10 完成 | Val R2: 0.7946\n",
      "Fold 9/10 完成 | Val R2: 0.8444\n",
      "Fold 10/10 完成 | Val R2: 0.5898\n",
      "\n",
      ">>> 十折交叉验证详细结果 (Per-Fold Results):\n",
      "       Fold  Train R2  Train RMSE  Train MAE  Val R2  Val RMSE  Val MAE\n",
      "0         1    0.9935      0.0501     0.0302  0.3909    0.4646   0.2447\n",
      "1         2    0.9926      0.0541     0.0320  0.8771    0.2021   0.1505\n",
      "2         3    0.9913      0.0587     0.0357  0.4785    0.3916   0.2311\n",
      "3         4    0.9899      0.0608     0.0388  0.6297    0.4585   0.2898\n",
      "4         5    0.9937      0.0489     0.0287  0.6821    0.3609   0.2655\n",
      "5         6    0.9912      0.0585     0.0357  0.8373    0.2469   0.1787\n",
      "6         7    0.9927      0.0537     0.0318  0.7180    0.2987   0.2168\n",
      "7         8    0.9921      0.0557     0.0327  0.7946    0.2552   0.1837\n",
      "8         9    0.9917      0.0555     0.0339  0.8444    0.2842   0.1837\n",
      "9        10    0.9921      0.0560     0.0333  0.5898    0.3438   0.2128\n",
      "10  Average    0.9921      0.0552     0.0333  0.6842    0.3307   0.2157\n",
      "\n",
      "==================================================\n",
      ">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\n",
      "==================================================\n",
      "\n",
      ">>> 模型性能最终汇总 (AdaBoost + BayesOpt):\n",
      "  Metric  CV Training (Avg)  CV Validation (Avg)  Test Set (Final)\n",
      "0    MAE             0.0333               0.2157            0.2230\n",
      "1   RMSE             0.0552               0.3307            0.3357\n",
      "2     R2             0.9921               0.6842            0.7105\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 引入贝叶斯优化库\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ==========================================\n",
    "# 1. 数据加载与分割 (80:20)\n",
    "# ==========================================\n",
    "file_path = 'C:/Users/tinid/polymer/major revision/通量标准化数据_无独热_Log变换12.18.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define excluded columns (unchanged)\n",
    "excluded_columns = ['log_Flux', 'polymer', 'DOI', 'Separation factor']\n",
    "X = data.drop(columns=excluded_columns, errors='ignore')\n",
    "y = data['log_Flux']\n",
    "\n",
    "# 划分出 20% 的独立测试集 (Test Set)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"原始数据总量: {len(X)}\")\n",
    "print(f\"用于调优和CV的训练集 (80%): {len(X_train_full)}\")\n",
    "print(f\"独立测试集 (20%): {len(X_test)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 构建预处理与模型流水线\n",
    "# ==========================================\n",
    "categorical_features = ['Permeation type']\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# 定义预处理器\n",
    "# 数值列：使用 'passthrough' (因已标准化)\n",
    "# 分类列：OneHotEncoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 定义基学习器 (Base Estimator)\n",
    "# AdaBoost 默认使用 DecisionTreeRegressor(max_depth=3)\n",
    "# 我们将在贝叶斯优化中调整它的 max_depth\n",
    "base_estimator = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# 定义 Pipeline: 预处理 -> AdaBoost\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', AdaBoostRegressor(estimator=base_estimator, random_state=42))\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 3. 第一阶段：贝叶斯超参数优化\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 1: 开始 AdaBoost 贝叶斯优化 (BayesSearchCV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 定义搜索空间\n",
    "# 注意：estimator__max_depth 是指 AdaBoost 内部决策树的深度\n",
    "search_spaces = {\n",
    "    'regressor__n_estimators': Integer(50, 500),          # 迭代次数\n",
    "    'regressor__learning_rate': Real(0.001, 1.0, prior='log-uniform'), # 学习率\n",
    "    'regressor__loss': Categorical(['linear', 'square', 'exponential']), # 损失函数\n",
    "    'regressor__estimator__max_depth': Integer(1, 10),    # 基学习器(树)的深度\n",
    "    'regressor__estimator__min_samples_split': Integer(2, 10) # 防过拟合\n",
    "}\n",
    "\n",
    "# 初始化贝叶斯搜索\n",
    "opt = BayesSearchCV(\n",
    "    pipeline,\n",
    "    search_spaces,\n",
    "    n_iter=30,      # 迭代 30 次\n",
    "    cv=5,           # 调优阶段内部 5 折\n",
    "    n_jobs=-1,      # 并行计算 (AdaBoost fit本身串行，但CV可并行)\n",
    "    random_state=42,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "opt.fit(X_train_full, y_train_full)\n",
    "end_time = time.time()\n",
    "\n",
    "best_estimator = opt.best_estimator_ # 包含预处理的完整 Pipeline\n",
    "best_params = opt.best_params_\n",
    "\n",
    "print(f\"贝叶斯优化耗时: {end_time - start_time:.2f} 秒\")\n",
    "print(\"\\n>>> 最佳参数:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 第二阶段：十折交叉验证 (使用最佳参数)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 2: 使用最佳参数进行十折交叉验证 (10-Fold CV)...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_full)):\n",
    "    # 4.1 切分数据\n",
    "    X_train_fold = X_train_full.iloc[train_idx]\n",
    "    y_train_fold = y_train_full.iloc[train_idx]\n",
    "    X_val_fold = X_train_full.iloc[val_idx]\n",
    "    y_val_fold = y_train_full.iloc[val_idx]\n",
    "    \n",
    "    # 4.2 克隆最佳模型 (确保每一折独立训练)\n",
    "    model = clone(best_estimator)\n",
    "    \n",
    "    # 4.3 训练 (Pipeline 自动处理 OneHot)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 4.4 预测\n",
    "    y_train_pred = model.predict(X_train_fold)\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    \n",
    "    # 4.5 记录指标\n",
    "    metrics = {\n",
    "        \"Fold\": fold + 1,\n",
    "        \"Train R2\": r2_score(y_train_fold, y_train_pred),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train_fold, y_train_pred)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train_fold, y_train_pred),\n",
    "        \"Val R2\": r2_score(y_val_fold, y_val_pred),\n",
    "        \"Val RMSE\": np.sqrt(mean_squared_error(y_val_fold, y_val_pred)),\n",
    "        \"Val MAE\": mean_absolute_error(y_val_fold, y_val_pred)\n",
    "    }\n",
    "    fold_results.append(metrics)\n",
    "    print(f\"Fold {fold+1}/10 完成 | Val R2: {metrics['Val R2']:.4f}\")\n",
    "\n",
    "# 输出详细表格\n",
    "df_cv_results = pd.DataFrame(fold_results)\n",
    "avg_row = df_cv_results.mean(numeric_only=True).to_frame().T\n",
    "avg_row[\"Fold\"] = \"Average\"\n",
    "df_final_cv = pd.concat([df_cv_results, avg_row], ignore_index=True)\n",
    "\n",
    "print(\"\\n>>> 十折交叉验证详细结果 (Per-Fold Results):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df_final_cv.round(4))\n",
    "\n",
    "# ==========================================\n",
    "# 5. 第三阶段：独立测试集最终评估\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\">>> Stage 3: 独立测试集 (Hold-out Test Set) 最终评估...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 使用 80% 的全量数据重新训练最佳模型\n",
    "best_estimator.fit(X_train_full, y_train_full)\n",
    "\n",
    "# 在 20% 独立测试集上预测\n",
    "y_test_pred = best_estimator.predict(X_test)\n",
    "\n",
    "final_summary = {\n",
    "    \"Metric\": [\"MAE\", \"RMSE\", \"R2\"],\n",
    "    \"CV Training (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Train MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Train RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Train R2\"]\n",
    "    ],\n",
    "    \"CV Validation (Avg)\": [\n",
    "        df_final_cv.iloc[-1][\"Val MAE\"],\n",
    "        df_final_cv.iloc[-1][\"Val RMSE\"],\n",
    "        df_final_cv.iloc[-1][\"Val R2\"]\n",
    "    ],\n",
    "    \"Test Set (Final)\": [\n",
    "        mean_absolute_error(y_test, y_test_pred),\n",
    "        np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        r2_score(y_test, y_test_pred)\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n>>> 模型性能最终汇总 (AdaBoost + BayesOpt):\")\n",
    "print(pd.DataFrame(final_summary).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b4da5-cbf9-494f-85e0-babacbb20e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
